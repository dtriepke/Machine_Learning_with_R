{
    "collab_server" : "",
    "contents" : "#================================================================\n# Autor: Dennis Triepke, Jan Grohn, Oliver Tebeck, Tanja M?nstedt\n# Datum: 22.11.2016\n# purpose: naive Bayes for classification\n#===============================================================\n\n# Default training data ======================================\n\n# training data\n#outlook <- c(\"sunny\", \"sunny\", \"overcast\", rep(\"rainy\",3), \"overcast\", \"sunny\", \"sunny\", \"rainy\", \"sunny\", \"overcast\", \"overcast\", \"rainy\")\n#temperature <- c(rep(\"hot\", 3), \"mild\", rep(\"cool\",3), \"mild\", \"cool\", \"mild\", \"mild\", \"mild\", \"hot\", \"mild\")\n#humidity <- c(rep(\"high\",4), rep(\"normal\",3), \"high\", rep(\"normal\",3), \"high\", \"normal\", \"high\")\n#windy <- c(\"FALSE\", \"TRUE\", rep(\"FALSE\",3), \"TRUE\", \"TRUE\", rep(\"FALSE\",3), \"TRUE\", \"TRUE\", \"FALSE\", \"TRUE\")\n#play <- c(\"no\", \"no\", rep(\"yes\", 3), \"no\", \"yes\", \"no\", rep(\"yes\", 5), \"no\")\n#data_train <- data.frame(outlook, temperature, humidity, windy, play)\n\n#new_data <- c(\"sunny\", \"hot\", \"high\", \"FALSE\")\n\n\n#new_data <- mydata\n#training_data =  data_train\n\n# Function that compute the naive Bayes classification =======\nnaiveBayes <- function(training_data, new_data){\n  \n  # detact class values for split\n  class_values <- unique(training_data[ , ncol(training_data)])\n  \n  # decicion table for saving results\n  posteriori_prob_tbl <- data.frame(class_values, condition = \"new_data\" , posterior_probabilities = 0)\n  \n  # compute prior probability for target classes and save in a table\n  priors <- table(training_data[, ncol(training_data)]) /  nrow(training_data) \n  \n  \n  #class_value = \"no\"\n  \n  for (class_value in class_values){\n    \n    # split test data w.r.t. the class values\n    splited_data <- split.data.frame(training_data, f = training_data[, ncol(training_data)], drop = FALSE)\n    class_table <- splited_data[[class_value]]\n    \n    # likelihood table (is refreshed in each iteration) \n    likelihood_prob_tbl <- data.frame(new_data, condition = class_value , conditional_probability = 0)\n    \n    #i = 4\n    \n    # loop for calculation the conditional probabilities for each attribute given the class_value\n    for (i in 1:length(new_data)){\n     \n      # for each attribute value in new_data compute probability under the condition of the class value \n      \n      # to avoit 0 probabilities (zero frequency) during the calculation of the \n      # maximum likelihood: \"Laplance k-Smooting\" \n      k <- 1 # smooting constant\n      d <- length(unique(training_data[,i]) ) # size of the considered attribute domaine  \n      count <- as.numeric( tapply(class_table[,ncol(class_table)], class_table[,i], length)[new_data[i]] )\n      count <- ifelse(is.na(count), 0, count) # ifelse function to avoit NA's\n      \n      # store each in a intermediate table \n      likelihood_prob_tbl[i, 3] <-  (count + k) / ( nrow(class_table) + k * d )\n    }\n \n\n    # help function for columns multiplication:\n    colMult <- function(x){\n      j <- 0\n      p <- 1\n      while(j < length(x)){\n        j <- j + 1\n        p <- p * x[j] }\n      return(p)\n    }\n    \n    \n    # compute the likelihood probability for the test data (new_data)   \n    likelihood_prob <- colMult(likelihood_prob_tbl$conditional_probability)\n  \n    # compute the posteriori probability by rule maximum likelihood x prior\n    posteriori_prob_tbl[posteriori_prob_tbl[,1] ==  class_value, 3] <- priors[class_value] * likelihood_prob\n    \n  }\n  \n  # decide by the class with the highest posterior probability\n  decicion <- as.character( posteriori_prob_tbl[ which.max(posteriori_prob_tbl$posterior_probabilities) , 1] )\n  p <- as.numeric(posteriori_prob_tbl[which.max(posteriori_prob_tbl$posterior_probabilities),3]   )\n  \n  # function output\n  #return(paste0(\"<class \",decicion, \" posteriori probability \",p, \">\") )\n  #return(posteriori_prob_tbl)\n  \n  return(decicion)\n}",
    "created" : 1489278975068.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2409650094",
    "id" : "82D42C12",
    "lastKnownWriteTime" : 1483134180,
    "last_content_update" : 1489279012311,
    "path" : "C:/Users/dtrie/Dropbox/Master - Statistik/Machine Learning/Assignment/Programming Assignment/Naive_Bayes/00_R_Code/01_Support_Functions.R",
    "project_path" : "01_Support_Functions.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}