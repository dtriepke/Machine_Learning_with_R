d <- length(unique(training_data[,i]) ) # size of the considered attribute domaine
count <- as.numeric( tapply(class_table[,ncol(class_table)], class_table[,i], length)[new_data[i]] )
count <- ifelse(is.na(count), 0, count) # ifelse function to avoit NA's
# store each in a intermediate table
likelihood_prob_tbl[i, 3] <-  (count + k) / ( nrow(class_table) + k * d )
}
# help function for columns multiplication:
colMult <- function(x){
j <- 0
p <- 1
while(j < length(x)){
j <- j + 1
p <- p * x[j] }
return(p)
}
# compute the likelihood probability for the test data (new_data)
likelihood_prob <- colMult(likelihood_prob_tbl$conditional_probability)
# compute the posteriori probability by rule maximum likelihood x prior
posteriori_prob_tbl[posteriori_prob_tbl[,1] ==  class_value, 3] <- priors[class_value] * likelihood_prob
}
posteriori_prob_tbl
decicion <- as.character( posteriori_prob_tbl[which.max(posteriori_prob_tbl$posterior_probabilities),1] )
decicion
posteriori_prob_tbl$posterior_probabilities
which.max(posteriori_prob_tbl$posterior_probabilities)
decicion
decicion
naiveBayes <- function(training_data, new_data){
# detact class values for split
class_values <- unique(training_data[ , ncol(training_data)])
# decicion table for saving results
posteriori_prob_tbl <- data.frame(class_values, condition = "new_data" , posterior_probabilities = 0)
# compute prior probability for target classes and save in a table
priors <- table(training_data[, ncol(training_data)]) /  nrow(training_data)
#class_value = "no"
for (class_value in class_values){
# split test data w.r.t. the class values
splited_data <- split.data.frame(training_data, f = training_data[, ncol(training_data)], drop = FALSE)
class_table <- splited_data[[class_value]]
# likelihood table (is refreshed in each iteration)
likelihood_prob_tbl <- data.frame(new_data, condition = class_value , conditional_probability = 0)
#i = 4
# loop for calculation the conditional probabilities for each attribute given the class_value
for (i in 1:length(new_data)){
# for each attribute value in new_data compute probability under the condition of the class value
# to avoit 0 probabilities (zero frequency) during the calculation of the
# maximum likelihood: "Laplance k-Smooting"
k <- 1 # smooting constant
d <- length(unique(training_data[,i]) ) # size of the considered attribute domaine
count <- as.numeric( tapply(class_table[,ncol(class_table)], class_table[,i], length)[new_data[i]] )
count <- ifelse(is.na(count), 0, count) # ifelse function to avoit NA's
# store each in a intermediate table
likelihood_prob_tbl[i, 3] <-  (count + k) / ( nrow(class_table) + k * d )
}
# help function for columns multiplication:
colMult <- function(x){
j <- 0
p <- 1
while(j < length(x)){
j <- j + 1
p <- p * x[j] }
return(p)
}
# compute the likelihood probability for the test data (new_data)
likelihood_prob <- colMult(likelihood_prob_tbl$conditional_probability)
# compute the posteriori probability by rule maximum likelihood x prior
posteriori_prob_tbl[posteriori_prob_tbl[,1] ==  class_value, 3] <- priors[class_value] * likelihood_prob
}
# decide by the class with the highest posterior probability
decicion <- as.character( posteriori_prob_tbl[ which.max(posteriori_prob_tbl$posterior_probabilities) , 1] )
p <- as.numeric(posteriori_prob_tbl[which.max(posteriori_prob_tbl$posterior_probabilities),3]   )
# function output
#return(paste0("<class ",decicion, " posteriori probability ",p, ">") )
#return(posteriori_prob_tbl)
return(decicion)
}
naiveBayes(training_data = data_train, new_data = new_data)
data_train
source("01_Support_Functions.R")
filename <- "car.data"
data <- read.csv2(paste0("ImportData/", filename), header = FALSE, sep = ",",
colClasses = rep("character", 7) )
colnames(data) <- c("buying", "maint", "doors", "persons", "low_boot", "safety", "class_values")
rep("character", 7)
set.seed(1807)
train <- sample(1:nrow(data), nrow(data) * 2/3 , replace = FALSE)
test <- -train
data_test <- data[test,]
data_train <- data[train,]
1:nrow(data)
nrow(data) * 2/3
train <- sample(1:nrow(data), nrow(data) * 2/3 , replace = FALSE)
test <- -train
test
data_test <- data[test,]
data_test <- data[test,]
data_train <- data[train,]
View(data_test)
data_test$estimated.class_values <- 0 # add new column for store the estimated class
row.names(data_test)
row.names(data_test)
j <- 1
instances_j <- data_test[j, - ncol(data_test)]
instances_j
ncol(data_test)
instances_j <- data_test[j, -c(7,8) ]
instances_j
instances_j <- as.character(instances_j) # test data needs to be a vector
instances_j
naiveBayes( training_data = data_train , new_data = instances_j)
}
naiveBayes( training_data = data_train , new_data = instances_j)
data_test[j, "estimated.class_values"] <-  naiveBayes( training_data = data_train , new_data = instances_j)
for (j in row.names(data_test)){
# data pre-processing
instances_j <- data_test[j, -c(7,8) ]
instances_j <- as.character(instances_j) # test data needs to be a vector
# run the naive Bayes function in order to estimate the class value and store the result in the
# data_test data frame
data_test[j, "estimated.class_values"] <-  naiveBayes( training_data = data_train , new_data = instances_j)
}
data_test[,"class_values"]
data_test[, "estimated.class_values"]
a %in% c("a", "b")
"a" %in% c("a", "b")
"a" %in% c("f", "b")
data_test[,"class_values"] != data_test[, "estimated.class_values"]
( data_test[,"class_values"] != data_test[, "estimated.class_values"] )*1
sum( ( data_test[,"class_values"] != data_test[, "estimated.class_values"] )*1 )
sum( ( data_test[,"class_values"] != data_test[, "estimated.class_values"] )*1 ) / nrow(data_test)
filename <- "car.data"
data <- read.csv2(paste0("ImportData/", filename), header = FALSE, sep = ",",
colClasses = rep("character", 7) )
colnames(data) <- c("buying", "maint", "doors", "persons", "low_boot", "safety", "class_values")
set.seed(1807)
train <- sample(1:nrow(data), nrow(data) * 2/3 , replace = FALSE)
test <- -train
data_test <- data[test,]
data_train <- data[train,]
data_test$estimated.class_values <- 0 # add new column for store the estimated class
data_test$estimated.class_values <- 0 # add new column for store the estimated class
A <- data.frame(changes = rep(0, 4))
A <- data.frame(changes = rep(0, 4))
for (in 1:4){
A[i] <- sample(1:4, 1, replace = FALSE)
};A
for (i in 1:4){
A[i] <- sample(1:4, 1, replace = FALSE)
};A
sample(1:4, 1, replace = FALSE)
A <- data.frame(changes = rep(0, 4))
for (i in 1:4){
A[i,] <- sample(1:4, 1, replace = FALSE)
};A
A <- data.frame(changes = rep(0, 4))
for (i in 1:4){
k <- sample(1:4, 1, replace = FALSE)
print(A[k,])
}
for (i in 1:4){
k <- sample(1:4, 1, replace = FALSE)
print(A[k,])
print(k)
}
A <- data.frame(changes = rep(0, 4))
for (i in 1:4){
k <- sample(1:4, 1, replace = FALSE)
print(A[k,])
print(paste("k=",k)
}
A <- data.frame(changes = rep(0, 4))
A
A <- data.frame(changes = 1:4)
for (i in 1:4){
k <- sample(1:4, 1, replace = FALSE)
print(A[k,])
print(paste("k=",k))
}
A <- data.frame(changes = 1:4)
for (i in 1:4){
k <- sample(1:4, 1, replace = FALSE)
print(A[k,])
print(paste("k=",k))
}
sum( ( data_test[,"class_values"] != data_test[, "estimated.class_values"] )*1 ) / nrow(data_test)
set.seed(1807)
train <- sample(1:nrow(data), nrow(data) * 2/3 , replace = FALSE)
test <- -train
data_test <- data[test,]
data_train <- data[train,]
for (j in row.names(data_test)){
# data pre-processing:
instances_j <- data_test[j, -c("class_values","estimated.class_values") ] # just the atrribute
instances_j <- as.character(instances_j) # test data needs to be a vector
# run the naive Bayes function in order to estimate the class value and store the result in the
# data_test data frame
data_test[j, "estimated.class_values"] <-  naiveBayes( training_data = data_train , new_data = instances_j)
}
colnames(data.test)
colnames(data_test)
data_test$estimated.class_values <- 0 # add new column for store the estimated class
!(colnames(data_test) %in% c("class_values","estimated.class_values"))
for (j in row.names(data_test)){
# data pre-processing:
# select the attribute columns (not the class columns)
instances_j <- data_test[j, !(colnames(data_test) %in% c("class_values","estimated.class_values")) ]
instances_j <- as.character(instances_j) # test data needs to be a vector
# run the naive Bayes function in order to estimate the class value and store the result in a
# new column in the test data frame
data_test[j, "estimated.class_values"] <-  naiveBayes( training_data = data_train , new_data = instances_j)
}
source
source("01_Support_Functions.R")
for (j in row.names(data_test)){
# data pre-processing:
# select the attribute columns (not the class columns)
instances_j <- data_test[j, !(colnames(data_test) %in% c("class_values","estimated.class_values")) ]
instances_j <- as.character(instances_j) # test data needs to be a vector
# run the naive Bayes function in order to estimate the class value and store the result in a
# new column in the test data frame
data_test[j, "estimated.class_values"] <-  naiveBayes( training_data = data_train , new_data = instances_j)
}
View(data_test)
sum( ( data_test[,"class_values"] != data_test[, "estimated.class_values"] )*1 ) / nrow(data_test)
# split data in training and test data
set.seed(1807)
train <- sample(1:nrow(data), nrow(data) * 2/3 , replace = FALSE)
test <- -train
data_test <- data[test,]
data_train <- data[train,]
# run the function ===========================================
# 1) estimate for each instances in the test data the class and compute
# the error rate of the classiﬁe
data_test$estimated.class_values <- 0 # add new column for store the estimated class
# select each row of the test data frame and estimate for each row based on the training data
# the class with the naiveBayes function
for (j in row.names(data_test)){
# data pre-processing:
# select the attribute columns (not the class columns)
instances_j <- data_test[j, !(colnames(data_test) %in% c("class_values","estimated.class_values")) ]
instances_j <- as.character(instances_j) # test data needs to be a vector
# run the naive Bayes function in order to estimate the class value and store the result in a
# new column in the test data frame
data_test[j, "estimated.class_values"] <-  naiveBayes( training_data = data_train , new_data = instances_j)
}
# error rate
sum( ( data_test[,"class_values"] != data_test[, "estimated.class_values"] )*1 ) / nrow(data_test)
# 0.1388889
error_rates <- c(1:100)
error_rates[1]
error_rates[4]
error_rates <- rep(0,100)
?set.seed
error_rates <- rep(0,100)
for (k in 1:100){
# split data in training and test data
#set.seed(1807)
train <- sample(1:nrow(data), nrow(data) * 2/3 , replace = FALSE)
test <- -train
data_test <- data[test,]
data_train <- data[train,]
# select each row of the test data frame and estimate for each row based on the training data
# the class with the naiveBayes function
data_test$estimated.class_values <- 0 # add new column for store the estimated class
for (j in row.names(data_test)){
# data pre-processing:
# select the attribute columns (not the class columns)
instances_j <- data_test[j, !(colnames(data_test) %in% c("class_values","estimated.class_values")) ]
instances_j <- as.character(instances_j) # test data needs to be a vector
# run the naive Bayes function in order to estimate the class value and store the result in a
# new column in the test data frame
data_test[j, "estimated.class_values"] <-  naiveBayes( training_data = data_train , new_data = instances_j)
}
# error rate
error_rates[k] <- sum( ( data_test[,"class_values"] != data_test[, "estimated.class_values"] )*1 ) / nrow(data_test)
}
error_rates
mean(error_rates)
plot(error_rates)
hist(error_rates)
table(data_test$class_values)
table(data_test$class_values + data_test$)
table(data_test$class_values + data_test$estimated.class_values)
xtabs(data_test$class_values ~ data_test$estimated.class_values)
data_test$class_values
data_test$estimated.class_values
?xtabs(data_test$class_values ~ data_test$estimated.class_values)
?xtabs(data_test[,7] ~ data_test[,8])
xtabs(data_test[,7] ~ data_test[,8])
xtabs(data_test[,7] + data_test[,8])
xtabs(~ data_test[,7] + data_test[,8])
confusion_matrix <- xtabs(~ data_test[,7] + data_test[,8])
names(confusion_matrix)
row.names(confusion_matrix)
as.data.frame(confusion_matrix)
A <- as.data.frame(confusion_matrix)
row.names(A)
col.names(A)
colnames(A)
colnames(A) <- c("actual class", "estimated_class", "Freq")
colnames(A)
A <- as.data.frame.character(confusion_matrix)
A
A <- as.data.frame(confusion_matrix)
colnames(A) <- c("actual class", "estimated_class", "Freq")
A
confusion_matrix <- xtabs(~ data_test[,7] + data_test[,8], dimnames = list(A = c("acc", "good",  "unacc", "vgood")))
confusion_matrix <- xtabs(~ class = data_test[,7] + B=data_test[,8])
confusion_matrix <- xtabs(~ class_Values + estimated.class_values, data_test)
confusion_matrix <- xtabs(~ class_values + estimated.class_values, data_test)
confusion_matrix
summary(confusion_matrix)
xtabs(A)
xtabs(Freq ~ ., A)
summary(xtabs(Freq ~ ., A) )
confusion_matrix
xtabs(Freq ~ ., A)
table(data_test$class_values + data_test$estimated.class_values)
(confusion_matrix <- xtabs(~ class_values + estimated.class_values, data_test) )
(confusion_matrix <- xtabs(~ class_values + estimated.class_values, data_test[, which(data_test$class_values == "acc")]) )
data_test[, which(data_test$class_values == "acc")]
which(data_test$class_values == "acc")
(confusion_matrix <- xtabs(~ class_values + estimated.class_values, data_test[which(data_test$class_values == "acc")]) )
(confusion_matrix <- xtabs(~ class_values + estimated.class_values, data_test[which(data_test$class_values == "acc"),]) )
data_test[which(data_test$class_values == "acc"),]
(confusion_matrix <- xtabs(~ class_values + estimated.class_values, data_test )
)
obs = c(sample(c(0,1),20,replace=TRUE),NA); obs = obs[order(obs)]
obs
obs
pred = runif(length(obs),0,1); pred = pred[order(pred)]
pred
confusion.matrix(obs,pred,threshold=0.5)
A <- c(1:4)
for (k in 1:4){
set.seed(1807)
print(sample(1:4,1))
}
for (k in 1:4){
set.seed(1807)
print(sample(1:4,1))
}
set.seed(1807)
for (k in 1:4){
print(sample(1:4,1))
}
set.seed(1807)
for (k in 1:4){
print(sample(1:4,1))
}
set.seed(1807)
for (k in 1:4){
print(sample(1:4,1))
}
for (k in 1:4){
print(sample(1:4,1))
}
for (k in 1:4){
print(sample(1:4,1))
}
for (k in 1:4){
print(sample(1:4,1))
}
# before running the loop below: take care it takes a long time
set.seed(1807); for (k in 1:100){
# split data in training and test data
#set.seed(1807)
train <- sample(1:nrow(data), nrow(data) * 2/3 , replace = FALSE)
test <- -train
data_test <- data[test,]
data_train <- data[train,]
# select each row of the test data frame and estimate for each row based on the training data
# the class with the naiveBayes function
data_test$estimated.class_values <- 0 # add new column for store the estimated class
for (j in row.names(data_test)){
# data pre-processing:
# select the attribute columns (not the class columns)
instances_j <- data_test[j, !(colnames(data_test) %in% c("class_values","estimated.class_values")) ]
instances_j <- as.character(instances_j) # test data needs to be a vector
# run the naive Bayes function in order to estimate the class value and store the result in a
# new column in the test data frame
data_test[j, "estimated.class_values"] <-  naiveBayes( training_data = data_train , new_data = instances_j)
}
# error rate
error_rates[k] <- sum( ( data_test[,"class_values"] != data_test[, "estimated.class_values"] )*1 ) / nrow(data_test)
}
# mean error rate
mean(error_rates)
source("01_Support_Functions.R")
filename <- "car.data"
data <- read.csv2(paste0("ImportData/", filename), header = FALSE, sep = ",",
colClasses = rep("character", 7) )
colnames(data) <- c("buying", "maint", "doors", "persons", "low_boot", "safety", "class_values")
set.seed(1807)
train <- sample(1:nrow(data), nrow(data) * 2/3 , replace = FALSE)
test <- -train
data_test <- data[test,]
data_train <- data[train,]
data_test$estimated.class_values <- 0 # add new column for store the estimated class
for (j in row.names(data_test)){
# data pre-processing:
# select the attribute columns (not the class columns)
instances_j <- data_test[j, !(colnames(data_test) %in% c("class_values","estimated.class_values")) ]
instances_j <- as.character(instances_j) # test data needs to be a vector
# run the naive Bayes function in order to estimate the class value and store the result in a
# new column in the test data frame
data_test[j, "estimated.class_values"] <-  naiveBayes( training_data = data_train , new_data = instances_j)
}
View(data_test)
duplicated(data[,-ncol(data)])
sum(duplicated(data[,-ncol(data)]))
sum(duplicated(data[,-ncol(data)])*1)
sum(unique(data[,-ncol(data)])*1)
sum(unique(data[,-ncol(data)]))
mean(data_test$class_values != data_test$estimated.class_values)
dag <- empty.graph( nodes = c("A", "B", "C", "D", "E"))
library(bnlearn)
dag <- empty.graph( nodes = c("A", "B", "C", "D", "E"))
arcs(dag) <- matrix(c("A", "B",
"A", "C",
"B", "D",
"C", "D",
"C", "E"),
byrow = TRUE, ncol = 2,
dimnames = list(NULL, c("from", "to")))
dag
arcs(dag)
A.prob <- array(c(0.2, 0.8), dim = 2, dimnames = list(A =  c("a1", "a2")))
B.prob <- array(c(0.8, 0.2, 0.2, 0.8), dim = c(2,2), dimnames = list(B = c("b1", "b2"),
A = c("a1", "a2")))
C.prob <- array(c(0.2, 0.8, 0.05, 0.95), dim = c(2,2), dimnames = list(C = c("c1", "c2"),
A = c("a1", "a2")))
D.prob <- array(c(0.8, 0.2, 0.8, 0.2, 0.8, 0.2, 0.05, 0.95), dim = c(2, 2, 2),
dimnames = list(D = c("d1", "d2"),C = c("c1", "c2"),  B = c("b1", "b2"))
)
E.prob <- array(c(0.8, 0.2, 0.6, 0.4), dim = c(2,2), dimnames = list(E = c("e1", "e2"),
E.prob
E.prob <- array(c(0.8, 0.2, 0.6, 0.4), dim = c(2,2), dimnames = list(E = c("e1", "e2"),
C = c("c1", "c2")))
E.prob <- array(c(0.8, 0.2, 0.6, 0.4), dim = c(2,2), dimnames = list(E = c("e1", "e2"),
C = c("c1", "c2")))
prob
prob <- list(A = A.prob, B = B.prob, C = C.prob, D= D.prob, E = E.prob)
prob
bn <- custom.fit(dag, prob)
bn
library(gRain)
dsep(bn, x = "B", y = "C", z = "D") # not d seperated
dsep(bn, x = "D", y = "A", z = c("B", "C"))
junction <- compile(as.grain(bn))
junction
querygrain(junction)
e1.E <- setEvidence(junction, nodes = "E", states = "e1")
querygrain(e1.E)
source("01_Support_Functions.R")
# Input data ================================================
filename <- "car.data"
data <- read.csv2(paste0("ImportData/", filename), header = FALSE, sep = ",",
colClasses = rep("character", 7) )
colnames(data) <- c("buying", "maint", "doors", "persons", "low_boot", "safety", "class_values")
# split data in training and test data
set.seed(1807)
train <- sample(1:nrow(data), nrow(data) * 2/3 , replace = FALSE)
test <- -train
data_test <- data[test,]
data_train <- data[train,]
data_test$estimated.class_values <- 0 # add new column for store the estimated class
for (j in row.names(data_test)){
# data pre-processing:
# select the attribute columns (not the class columns)
instances_j <- data_test[j, !(colnames(data_test) %in% c("class_values","estimated.class_values")) ]
instances_j <- as.character(instances_j) # test data needs to be a vector
# run the naive Bayes function in order to estimate the class value and store the result in a
# new column in the test data frame
data_test[j, "estimated.class_values"] <-  naiveBayes( training_data = data_train , new_data = instances_j)
}
mean(data_test$class_values != data_test$estimated.class_values)
(confusion_matrix <- xtabs(~ class_values + estimated.class_values, data_test) )
library(bnlearn)
dag <- empty.graph( nodes = c("A", "B", "C", "D", "E"))
arcs(dag) <- matrix(c("A", "B",
"A", "C",
"B", "D",
"C", "D",
"C", "E"),
byrow = TRUE, ncol = 2,
dimnames = list(NULL, c("from", "to")))
arcs(dag)
A <- c("a1", "a1", rep("a2",4), "a3", "a3")
B <- c(rep("b1", 4), "b3", "b3", "b1", "b2")
C <- c("c1", "c2", "c2", "c3", "c2", "c3", "c2", "c2" )
mydata <- data.frame (A,B,C)
mydata
A <- c(rep("a1", 12), rep("a2", 12))
B <- c(rep(c("b1", "b2"), each = 6, 2))
C <- c( rep("c1", 4), "c2", "c2", rep("c1", 3), rep("c2", 3),
rep("c1", 3), rep("c2", 3),  rep("c1", 2), rep("c2", 4) )
mydata <- data.frame(C, B, A)
table(mydata)
mydata
source("01_Support_Functions.R")
filename <- "car.data"
data <- read.csv2(paste0("ImportData/", filename), header = FALSE, sep = ",",
colClasses = rep("character", 7) )
colnames(data) <- c("buying", "maint", "doors", "persons", "low_boot", "safety", "class_values")
data
set.seed(1807)
train <- sample(1:nrow(data), nrow(data) * 2/3 , replace = FALSE)
test <- -train
data_test <- data[test,]
data_train <- data[train,]
data_test$estimated.class_values <- 0 # add new column for store the estimated class
